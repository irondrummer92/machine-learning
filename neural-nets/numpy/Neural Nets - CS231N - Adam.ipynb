{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO\n",
    "- <strike>CV Error plots</strike>\n",
    "- <strike>Zero centering of data</strike>\n",
    "- <strike>L1/L2 regularization</strike>\n",
    "- <strike>Xavier initialization (to avoid dead neurons in Sigmoids/Tanh)</strike>\n",
    "- <strike>He et.al initiliazation (to avoid dead neurons in ReLUs)</strike>\n",
    "- <strike>Momentum/Nesterov Momentum</strike>\n",
    "- Adam\n",
    "- Benchmark current Algorithm on CIFAR - 10 dataset\n",
    "- Dropout (Inverted Dropout)\n",
    "- Batch Norm\n",
    "- HyperOpt\n",
    "- Convolution Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "from matplotlib import pyplot as plt\n",
    "from mnist import MNIST as mn\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def centerData2(inputMatrix):\n",
    "    \n",
    "    \"\"\"Center each variable to 0\"\"\"\n",
    "    # (x - mu)/sigma. Data is now centered at 0\n",
    "    \n",
    "    # Calculate mean and variance for each input feature\n",
    "    variableMeans = np.mean(inputMatrix, axis = 0)\n",
    "    \n",
    "    # Centering with mean and return\n",
    "    centerData = inputMatrix - variableMeans\n",
    "    return centerData,variableMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lookup table of activation functions and derivatives\n",
    "actLookup = {\"sigmoid\":lambda x: 1/(1 + np.exp(-1 * x)),\n",
    "             \"tanh\":lambda x: np.tanh(x),\n",
    "            \"relu\": lambda x: np.maximum(0,x)}\n",
    "\n",
    "derivativeLookup = {\"sigmoid\": lambda x: x * (1.-x),\n",
    "               \"tanh\": lambda x: 1. - (np.tanh(x) ** 2),\n",
    "              \"relu\": lambda x: np.ceil(x.clip(0,1))}\n",
    "\n",
    "# Weight Initialization strategy\n",
    "# Random multiplies the initializations by a small number\n",
    "# Xavier 1/sqrt(numInputs)\n",
    "# For relu's, initalization is as recommended by He et. al(2015)\n",
    "weightLookup = {\"random\":lambda x:0.01,\n",
    "               \"xavier\":lambda x:1/sqrt(x),\n",
    "               \"he.et.al\":lambda x:2/np.sqrt(x)}\n",
    "\n",
    "# Regularization error component,\n",
    "# 0 if none, sum(x^2) if L2 and sum(|x|) if L1\n",
    "regLookup = {\"none\":lambda x: 0,\n",
    "            \"l2\": lambda x: 0.5 * (x ** 2).sum(),\n",
    "            \"l1\" : lambda x:sum(abs(x))}\n",
    "\n",
    "# Derivatives of regularization terms\n",
    "regDerivLookup = {\"none\": lambda x:0,\n",
    "                \"l2\": lambda x: x,\n",
    "                \"l1\": lambda x: 1}\n",
    "\n",
    "# Momentum rate update\n",
    "momentumLookup = {\"none\":0,\n",
    "                  \"momentum\":lambda x:1,\n",
    "                  \"nag\": lambda x: (1+x)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class layer(object):\n",
    "    # A neural net layer with n neurons as defined by the user and an activation function for the layer\n",
    "    \n",
    "    def __init__(self,numInputs, layerSize, actFun = \"sigmoid\", weightInit = \"random\"):\n",
    "    \n",
    "        # Size of the layer and the number of inputs\n",
    "        self.layerSize = layerSize\n",
    "        self.actFun = actLookup[actFun]\n",
    "        self.deriv = derivativeLookup[actFun]\n",
    "\n",
    "        # Incorporating the bias neuron\n",
    "        self.numInputs = numInputs + 1\n",
    "        self.inputMatrix = None\n",
    "        \n",
    "        # Numpy matrix of weights\n",
    "        np.random.seed(seed=10000)\n",
    "        self.weights = np.array(np.random.randn(self.layerSize,self.numInputs))/100 * \\\n",
    "        weightLookup[weightInit](self.numInputs)\n",
    "        \n",
    "        # Set the backward propagation values for this layer\n",
    "        self.delta = None\n",
    "        \n",
    "        # Various components of learning methods (Momentum/NAG)\n",
    "        self.velocity = np.zeros(self.weights.shape)\n",
    "        self.vPrev = self.velocity\n",
    "        self.m = np.zeros(self.weights.shape)\n",
    "               \n",
    "        \n",
    "    # Defining the forward function to the layer\n",
    "    def forward(self, inputMatrix):\n",
    "        \"\"\"Forward() forward propagates the inputs to a layer\"\"\"\n",
    "        \n",
    "        # Convert to numpy array if not passed as a numpy array\n",
    "        if(not(isinstance(inputMatrix,np.ndarray))):\n",
    "            inputMatrix = np.array(inputMatrix)\n",
    "        \n",
    "        rows, columns = inputMatrix.shape\n",
    "        \n",
    "        # Dot product of input matrix (with extra 1s for the bias neuron) with the weight matrix\n",
    "        inputPadded = np.append(np.ones(rows).reshape(rows,1), inputMatrix, axis = 1)\n",
    "        self.inputMatrix = inputPadded\n",
    "        layerOutput = np.dot(inputPadded, self.weights.T)\n",
    "        \n",
    "        # Pass through activation function\n",
    "        self.output = self.actFun(layerOutput)\n",
    "        return self.output\n",
    "    \n",
    "    # Defining the backward propagation function\n",
    "    def backward(self, delta):\n",
    "        \"\"\"Backward takes the delta from next layer and passes it on the previous layer\"\"\"        \n",
    "\n",
    "        # Delta passed back is wkh * deltak for every batch instance\n",
    "        # Delta for each batch element is sum by column of the delta matrix passed back\n",
    "        # by the next layer\n",
    "\n",
    "        self.delta = np.multiply(self.deriv(self.output),delta)\n",
    "        \n",
    "        # Delta to pass on to preceding layer has to be \n",
    "        # matrix multiplication of these values by the weight matrix\n",
    "        weightMatrix = self.weights[:,1:]\n",
    "        \n",
    "        # deltaBack = weightMatrix.T.dot(self.delta.T)\n",
    "        deltaBack = self.delta.dot(weightMatrix)\n",
    "        return deltaBack\n",
    "    \n",
    "    def updateWeights(self, learnRate,\n",
    "                      regularize = \"none\", lambdaReg = 0.01,\n",
    "                      learningMethod = \"none\", mu = 0.9,\n",
    "                      adam = 0, beta1 = 0.9, beta2 = 0.999, eps = 1e-8, t = 1):\n",
    "        \"\"\"updateWeights() uses the inputs and the delta stored in each layer after forward\n",
    "        and backward propagation to derive the weight update rule\"\"\"\n",
    "        \n",
    "        regDeriv = regDerivLookup[regularize]\n",
    "        # The udpate rule for eachelement in the matrix is given by\n",
    "        # wi = wi + sum_over_instances(delta for neuron * input i to neuron * learning rated)\n",
    "        # Compute the weight updates for every data point and then add those updates\n",
    "        rows,columns = self.inputMatrix.shape\n",
    "        stepGradient = -1. * np.dot(self.inputMatrix.T,self.delta).T * (1/np.float(rows))\n",
    "        \n",
    "        # Regularization if applicable\n",
    "        stepGradient = np.add(stepGradient, lambdaReg * regDeriv(self.weights))\n",
    "        \n",
    "        # Weight updates for adam\n",
    "        self.m = beta1 * np.float(adam) * self.m \\\n",
    "        + ((1. - beta1) * adam + (1. - adam) * (-learnRate)) * stepGradient\n",
    "        \n",
    "        weightUpdates = self.m\n",
    "                \n",
    "        # Different learning methods\n",
    "        self.vPrev = self.velocity\n",
    "    \n",
    "        # Momentum using adam\n",
    "        self.velocity = (beta2 * adam + (1.-adam) * mu) * self.velocity \\\n",
    "        + (1. - beta2) * adam * (stepGradient ** 2) \\\n",
    "        + (1. - adam) * weightUpdates\n",
    "\n",
    "        # Change weightUpdates based on the learning rate\n",
    "        weightUpdates = (1. - adam) * \\\n",
    "        np.add(weightUpdates, momentumLookup[learningMethod](mu)  * self.velocity)\n",
    "        \n",
    "        # If NAG is chosen, additional term gets added\n",
    "        weightUpdates = (1. - adam) * \\\n",
    "        np.subtract(weightUpdates, (mu if learningMethod == \"nag\" else 0.) * self.vPrev)\n",
    "        \n",
    "        # Bias correction for Adam\n",
    "        self.m = self.m/(1. - beta1 ** t)\n",
    "        self.velocity = self.velocity * ((1 - adam) + adam * (1./(1. - beta2 ** t)))\n",
    "    \n",
    "        \n",
    "        # If adam update is chosen\n",
    "        adamUpdate = -adam * learnRate * self.m / (np.sqrt(np.float(adam) * self.velocity) + eps)\n",
    "                \n",
    "        \n",
    "        # Final Weight updates\n",
    "        self.weights = np.add(self.weights, np.float(adam) * adamUpdate + (1. - adam) * weightUpdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class neuralNet(object):\n",
    "    \n",
    "    \"\"\"Neural net object is a combination of layer objects. Has 2 functions\n",
    "    predict and backprop\"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "    def __init__(self, layerList, actFun = \"sigmoid\", weightInit = \"random\"):\n",
    "        \n",
    "        \"\"\"Takes in the layerlist as input and generates as many layers\"\"\"\n",
    "        \n",
    "        self.actFun = actFun\n",
    "        \n",
    "        # Creating the layers\n",
    "        self.layers = [layer(numInputs=layerList[i - 1],\n",
    "                             layerSize=layerList[i],                            \n",
    "                             actFun=self.actFun,\n",
    "                            weightInit = weightInit) for i in range(1, len(layerList))]\n",
    "        self.cvError = None\n",
    "        self.regLoss= None\n",
    "        \n",
    "    def predict(self, inputMatrix):\n",
    "        \"\"\"Predict function is used to propagate the inputs from \n",
    "        one layer to the next and get the final output from the layer\"\"\"\n",
    "        # Pass on input of previous layer to the next\n",
    "        # If 1st hidden layer, pass on the input\n",
    "        layerOut = inputMatrix\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            layerOut = layer.forward(inputMatrix=layerOut)\n",
    "            \n",
    "        return layerOut\n",
    "    \n",
    "    def computeError(self, inputs, outputs):\n",
    "        \n",
    "        predictions = self.predict(inputs)\n",
    "        numRows = inputs.shape[0]\n",
    "        # Calculate deltas and sum squares\n",
    "        delta = np.subtract(predictions,outputs)\n",
    "        totalError = np.sum(delta**2)/numRows\n",
    "        return totalError\n",
    "    \n",
    "    def computeRegularizationLoss(self, regularize, lambdaReg):\n",
    "        # Calculate layerWise sums and get total\n",
    "        regLossFunction  = regLookup[regularize]       \n",
    "        layerRegs = np.array([lambdaReg * regLossFunction(layer.weights) for layer in self.layers])\n",
    "        return(layerRegs.sum())\n",
    "    \n",
    "    def backprop(self, trainInput, trainOutput, learnRate, \n",
    "                 testInput,testOutput,\n",
    "                 batchSize = 1, nIter = 100, \n",
    "                 showStep = 1000, stepError = 1000,\n",
    "                 regularize = \"none\",lambdaReg = 0.01,\n",
    "                 learningMethod = \"none\", mu = 0.9,\n",
    "                 adam = 0, beta1 = 0.9, beta2 = 0.999, eps = 1e-8):\n",
    "        \n",
    "        \"\"\"Back prop is used to update the 2000weights based on the training sample\n",
    "        It runs nIter iterations on the trainInput with batchSize number of rows\n",
    "        Weight updates are carried out at learning rate learnRate\"\"\"\n",
    "        \n",
    "        if(not(isinstance(trainOutput,np.ndarray))):\n",
    "            trainOutput = np.array(trainOutput)\n",
    "        if(not(isinstance(trainInput,np.ndarray))):\n",
    "            trainInput = np.array(trainInput)\n",
    "        \n",
    "        rows, columns = trainInput.shape\n",
    "        \n",
    "        # initialize empty CV error matrix: Column 1 represents Train Error\n",
    "        # Column 2 represents Test Error\n",
    "        self.cvError = np.zeros(nIter/stepError * 2).reshape(nIter/stepError,2)\n",
    "        \n",
    "        self.regLoss = np.zeros(nIter/stepError * 2).reshape(nIter/stepError,2)\n",
    "        \n",
    "        for i in range(nIter):\n",
    "            \n",
    "            if((i + 1) % showStep == 0):\n",
    "                print i + 1\n",
    "                \n",
    "            if((i + 1) % stepError == 0):\n",
    "                self.cvError[((i + 1) / stepError)-1] = [self.computeError(trainInput,trainOutput),\n",
    "                                   self.computeError(testInput,testOutput)]\n",
    "                \n",
    "                self.regLoss[((i + 1) / stepError)-1] = [self.computeRegularizationLoss(regularize = regularize,\n",
    "                                                                                        lambdaReg = lambdaReg)]\n",
    "            \n",
    "            # Pick a random sample from the trainInput and trainOutput\n",
    "            # Updated weights based on the same. Sample size is to be of size batchSize\n",
    "            \n",
    "            randomIndices = np.random.choice(range(rows),size=batchSize)\n",
    "            \n",
    "            # Sample from trainInput and trainOutput\n",
    "            batchTrain = trainInput[randomIndices,:].reshape(batchSize,columns)\n",
    "            batchTest = trainOutput[randomIndices,:]\n",
    "        \n",
    "            # A forward pass through the network\n",
    "            output = self.predict(batchTrain)\n",
    "            \n",
    "            # Iterate backwards through the layers to pass the deltas\n",
    "            delta = np.subtract(batchTest,output)\n",
    "            \n",
    "            for layer in self.layers[::-1]:\n",
    "                \n",
    "                # Delta to be passed to the previous layer is computed\n",
    "                delta = layer.backward(delta=delta)\n",
    "                # Update weights as determined by the delta gradient\n",
    "                layer.updateWeights(learnRate=learnRate, \n",
    "                                    regularize = regularize, lambdaReg = lambdaReg,\n",
    "                                    learningMethod = learningMethod, mu = mu,\n",
    "                                    adam = adam, beta1 = beta1, beta2 = beta2, eps = eps, t = i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdata = mn(path='../datasets/MNIST/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images,labels = mdata.load_training()\n",
    "images = np.array(images)/255.\n",
    "labels = np.array(labels).reshape(60000,1).astype(dtype = 'uint8')\n",
    "labels = np.unpackbits(labels,axis=1)\n",
    "labels = labels[:,4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleIndices = np.random.choice(range(len(images)),size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageTrain = images[sampleIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelTrain = labels[sampleIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testImages,testLabels = mdata.load_testing()\n",
    "testImages = np.array(testImages)/255.\n",
    "testLabelsDigit = np.array(testLabels).reshape(10000,1).astype(dtype = 'uint8')\n",
    "testLabels = np.unpackbits(testLabelsDigit,axis=1)\n",
    "testLabels = testLabels[:,4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleTestIndices = np.random.choice(range(len(testImages)), 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imageTest = testImages[sampleTestIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelTestDigit = testLabelsDigit[sampleTestIndices]\n",
    "labelTest = testLabels[sampleTestIndices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not improving accuracy\n",
    "# centerTrain, trainMeans = centerData2(imageTrain)\n",
    "# centerTest = imageTest - trainMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training a neural net with 256 inputs, 300 hidden units (1 layer only)\n",
    "nn3 = neuralNet(layerList=[784,300,4],actFun=\"relu\",weightInit=\"he.et.al\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "nn3.backprop(batchSize=5,learnRate=0.01,nIter=50000,showStep=5000,stepError=40,\n",
    "             trainOutput=labelTrain,testOutput=labelTest,trainInput=imageTrain,testInput=imageTest,\n",
    "             learningMethod=\"nag\",mu=0.9,adam = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.948]\n"
     ]
    }
   ],
   "source": [
    "# Compute accuracy of digit recognition\n",
    "preds = nn3.predict(imageTest)\n",
    "preds = np.array([np.round(arr) for arr in preds])\n",
    "preds = np.append(np.zeros(8000).reshape(2000,4),preds,axis=1)\n",
    "predDigits = np.packbits(preds.astype(\"bool\"))\n",
    "acc = [predDigits[i] == labelTestDigit[i] for i in range(2000)]\n",
    "print sum(acc)/2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhIAAAFkCAYAAAB1rtL+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f29ed0cff10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn3.cvError[:,0],'r',label = 'train')\n",
    "plt.plot(nn3.cvError[:,1],'g',label = 'test')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
